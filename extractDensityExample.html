<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Matthew Leonawicz" />


<title>Minimal Empirical Density Estimation</title>

<script src="libs/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link href="libs/bootstrap-2.3.2/css/united.min.css" rel="stylesheet" />
<link href="libs/bootstrap-2.3.2/css/bootstrap-responsive.min.css" rel="stylesheet" />
<script src="libs/bootstrap-2.3.2/js/bootstrap.min.js"></script>
<style type="text/css">

/* padding for bootstrap navbar */
body {
  padding-top: 50px;
  padding-bottom: 40px;
}
@media (max-width: 979px) {
  body {
    padding-top: 0;
  }
}

/* offset scroll position for anchor links (for fixed navbar)  */
@media (min-width: 980px) {
  .section h2 {
    padding-top: 52px;
    margin-top: -52px;
  }
  .section h3 {
    padding-top: 52px;
    margin-top: -52px;
  }
}


/* don't use link color in navbar */
.dropdown-menu>li>a {
  color: black;
}

/* some padding for disqus */
#disqus_thread {
  margin-top: 45px;
}

</style>

<link rel="stylesheet" href="libs/font-awesome-4.1.0/css/font-awesome.min.css"/>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #303030; color: #cccccc; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; }
td.sourceCode { padding-left: 5px; }
pre, code { color: #cccccc; background-color: #303030; }
code > span.kw { color: #f0dfaf; }
code > span.dt { color: #dfdfbf; }
code > span.dv { color: #dcdccc; }
code > span.bn { color: #dca3a3; }
code > span.fl { color: #c0bed1; }
code > span.ch { color: #dca3a3; }
code > span.st { color: #cc9393; }
code > span.co { color: #7f9f7f; }
code > span.ot { color: #efef8f; }
code > span.al { color: #ffcfaf; }
code > span.fu { color: #efef8f; }
code > span.er { color: #c3bf9f; }
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>



<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-46129458-3', 'auto');
  ga('send', 'pageview');

</script>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="container-fluid main-container">

<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-inner">
    <div class="container">
      <button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="brand" href="index.html">Data Extraction</a>
      <div class="nav-collapse collapse">
        <ul class="nav">
          <li class="dropdown">
            <a href="extraction-evaluation" class="dropdown-toggle" data-toggle="dropdown">Extraction evaluation <b class="caret"></b></a>
            <ul class="dropdown-menu">
              <li class="nav-header">Project</li>
              <li><a href="eval_intro.html">Introduction</a></li>
              <li><a href="eval_case.html">Case study: sample mean</a></li>
              <li><a href="eval_res.html">Results</a></li>
              <li><a href="eval_next.html">Next steps</a></li>
              <li class="divider"></li>
              <li class="nav-header">R Code</li>
              <li><a href="extract_eval_code.html">Complete code</a></li>
            </ul>

          <li class="dropdown">
            <a href="density-estimation" class="dropdown-toggle" data-toggle="dropdown">Density estimation <b class="caret"></b></a>
            <ul class="dropdown-menu">
              <li class="nav-header">Project</li>
              <li><a href="dens_intro.html">Introduction</a></li>
              <li><a href="dens_sims.html">Simulations</a></li>
              <li class="divider"></li>
              <li class="nav-header">Use cases</li>
              <li><a href="dens_use1.html">Case 1: Climate</a></li>
              <li><a href="dens_use2.html">Case 2: Vegetation</a></li>
              <li class="divider"></li>
              <li class="nav-header">R code</li>
              <li><a href="dens_sims_code.html">Basic simulation</a></li>
            </ul>

          <li class="dropdown">
            <a href="pre-indexing" class="dropdown-toggle" data-toggle="dropdown">Pre-indexing <b class="caret"></b></a>
            <ul class="dropdown-menu">
              <li class="nav-header">Project</li>
              <li><a href="ind_intro.html">Introduction</a></li>
              <li><a href="ind_related.html">Related items</a></li>
              <li class="divider"></li>
              <li class="nav-header">R Code</li>
              <li><a href="ind_code.html">Complete code</a></li>
            </ul>

          <li><a href="http://leonawicz.github.io">All Projects</a></li>
        </ul>
        <ul class="nav pull-right">
          <a class="btn btn-primary" href="https://github.com/leonawicz/DataExtraction">
            <i class="fa fa-github fa-lg"></i>
            Github
          </a>
        </ul>
      </div><!--/.nav-collapse -->
    </div>
  </div>
</div>

<div id="header">
<h1 class="title">Minimal Empirical Density Estimation</h1>
<h4 class="author"><em>Matthew Leonawicz</em></h4>
</div>


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Here I explore basic kernel density estimation in <strong>R</strong> as a way to empirically estimate densities for data extracted from common SNAP data sets. This is just a toy example where I use simple simulations to investigate properties I am most interested in for the estimated distributions.</p>
<div id="motivation" class="section level3">
<h3>Motivation</h3>
<p>I often face the real-world problem of needing to rapidly summarize large amounts of data in an efficient manner without losing, skewing, or obscuring too much information. The context for this simulation is to show that it is possible to estimate an empirical distribution of a variable by a small set of points roughly defining the density curve, which can then we used in conjunction with linear approximation and bootstrap resampling to simulate new draws from the estimated distribution. The process can stop here if it is a sample that is required, or, in turn, an arbitrarily large sample drawn can be used to re-estimate the density more smoothly.</p>
<p>For some applications this is not useful, as the original data are already available. Their distribution can be estimated in the most appropriate manner the first time around. However, this delay in the chain of data propagation is extremely helpful when I am trying to provide real-time summaries of large data sets on demand, the quintessential example being my <strong>R</strong> Shiny web applications.</p>
<p>Particularly, in the case of trying to rapidly summarize and graph full distributional information, as opposed to, say, a time series of mean values, some form of data reduction must take place upstream from the web application. At SNAP, we have long time series of high spatial resolution data that are too much to dump into a simple web application. Data can easily be externalized and specific data sets sourced by an app on demand, but it is especially helpful to avoid the crippling load times associated with forcing massive amounts of data into an app while a user is trying to interact with it.</p>
<p>Instead of loading a dataset, e.g., an R workspace file, containing a huge sample of data for some variable, it is much easier to:</p>
<ul>
<li>store a small, efficient, and hopefully, accurate and precise representation of that data,</li>
<li>load only that into the Shiny app,</li>
<li>and then have <strong>R</strong> quickly explode that representation into a new simulated data set.</li>
</ul>
<p>This is especially an effective approach in the context of Shiny apps where the goal is to visually explore patterns and present information, and not to have tunnel vision for an exact value buried deep in a massive data set which is nevertheless riddled with uncertainty.</p>
</div>
<div id="details" class="section level3">
<h3>Details</h3>
<p>Currently a simple simulation is shown, followed by two typical use cases in which application of such a strategy proves very beneficial. For the use cases, <strong>R</strong> code is provided to show how this is done in practice with real data inthe context of actual projects.</p>
<div id="limitations" class="section level4">
<h4>Limitations</h4>
<p>The simulation is obviously not a robust analysis. Rather it is intended as a simple illustration of the process being utilized for data reduction in specific applications.</p>
</div>
</div>
</div>
<div id="related-items" class="section level2">
<h2>Related items</h2>
<div id="files-and-data" class="section level3">
<h3>Files and Data</h3>
<p>There are no files or data related to the simulation itself. It is self-contained and reproducible. For the use cases, references are made to other projects which can be explored further.</p>
</div>
</div>
<div id="r-code" class="section level2">
<h2>R code</h2>
<div id="setup" class="section level3">
<h3>Setup</h3>
<p>First simulate some data and perform some rudimentary density estimation.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">47</span>)
x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rnorm</span>(<span class="dv">1000</span>, -<span class="dv">3</span>, <span class="dv">1</span>), <span class="kw">rnorm</span>(<span class="dv">500</span>, -<span class="dv">1</span>, <span class="dv">1</span>), <span class="kw">rpois</span>(<span class="dv">500</span>, <span class="dv">10</span>))  <span class="co"># Simulate multimodal distribution</span>

n &lt;-<span class="st"> </span><span class="dv">20</span>  <span class="co"># default for density() is n=512</span>
den.smooth &lt;-<span class="st"> </span><span class="kw">density</span>(x, <span class="dt">adjust =</span> <span class="fl">1.5</span>, <span class="dt">n =</span> n)  <span class="co"># I tend to smooth it a bit</span>
den &lt;-<span class="st"> </span><span class="kw">density</span>(x, <span class="dt">adjust =</span> <span class="dv">1</span>, <span class="dt">n =</span> n)  <span class="co"># But I store one without additional smoothing</span></code></pre>
</div>
<div id="graph-results" class="section level3">
<h3>Graph results</h3>
<p>The first plot shows a histogram of the original simulated data, overlain with boostrap resamples drawn from the crudely estimated density, and finally, a new density estimation performed post-bootstrap. The second plot shows the same, but incorporates an intermediary step involving linear approximation. This allows the subsequent draws to be more continuous.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># win.graph(10,5) layout(matrix(1:2,1,2))</span>

<span class="co"># hist(x, freq=F) lines(den.smooth, lwd=2) # my preferred smoothed density</span>
<span class="co"># estimate based on x</span>

<span class="kw">hist</span>(x, <span class="dt">freq =</span> F)
for (i in <span class="dv">1</span>:<span class="dv">1000</span>) {
    <span class="co"># reproducing a sample from distribution of x based on den which I carry</span>
    <span class="co"># through my code</span>
    sample.boot &lt;-<span class="st"> </span><span class="kw">sample</span>(den$x, <span class="dt">size =</span> <span class="dv">1000</span>, <span class="dt">prob =</span> den$y, <span class="dt">rep =</span> T)
    <span class="kw">lines</span>(<span class="kw">density</span>(sample.boot, <span class="dt">adjust =</span> <span class="dv">1</span>), <span class="dt">lwd =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;#FF000001&quot;</span>)  <span class="co"># No extra smoothing with smaller samples</span>
    <span class="co"># print(i)</span>
}
<span class="co"># A larger bootstrap sample will pin down the distribution accurately enough</span>
<span class="co"># if necessary</span>
sample.boot &lt;-<span class="st"> </span><span class="kw">sample</span>(den$x, <span class="dt">size =</span> <span class="dv">10000</span>, <span class="dt">prob =</span> den$y, <span class="dt">rep =</span> T)
<span class="kw">lines</span>(<span class="kw">density</span>(sample.boot, <span class="dt">adjust =</span> <span class="fl">1.5</span>), <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;#FF0000&quot;</span>)  <span class="co"># smoothing affordable</span></code></pre>
<p><img src="extractDensityExample_files/figure-html/plot1-1.png" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># As before but adding an approx() step</span>
<span class="kw">hist</span>(x, <span class="dt">freq =</span> F)
for (i in <span class="dv">1</span>:<span class="dv">1000</span>) {
    ap &lt;-<span class="st"> </span><span class="kw">approx</span>(den$x, den$y, <span class="dt">n =</span> <span class="dv">1000</span>)  <span class="co"># reintroduce interpolation before sampling</span>
    sample.boot2 &lt;-<span class="st"> </span><span class="kw">sample</span>(ap$x, <span class="dt">size =</span> <span class="dv">1000</span>, <span class="dt">prob =</span> ap$y, <span class="dt">rep =</span> T)
    <span class="kw">lines</span>(<span class="kw">density</span>(sample.boot2, <span class="dt">adjust =</span> <span class="dv">1</span>), <span class="dt">lwd =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;#0000FF01&quot;</span>)
    <span class="co"># print(i)</span>
}
sample.boot2 &lt;-<span class="st"> </span><span class="kw">sample</span>(ap$x, <span class="dt">size =</span> <span class="dv">10000</span>, <span class="dt">prob =</span> ap$y, <span class="dt">rep =</span> T)
<span class="kw">lines</span>(<span class="kw">density</span>(sample.boot2, <span class="dt">adjust =</span> <span class="dv">1</span>), <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;#0000FF&quot;</span>)</code></pre>
<p><img src="extractDensityExample_files/figure-html/plot2-1.png" /></p>
</div>
</div>
<div id="use-case-1-climate" class="section level2">
<h2>Use case 1: Climate</h2>
<p>Temperature and precipition data from SNAP’s downscaled climate models are often used to make inferences about future trends and uncertainty among potential climate scenarios. This generally is done by looking at specific statistics culled from the model outputs, usually the mean value over some combination of factors of interest such as seasonal period or geographical region. But what about when we want to look at an entire distribution of data at once? Furthermore, we want to visualize many distributions in quick succession, distributions of temperature or precipitation from different months, seasons, years, decades, locations, climate models, scenarios, etc.</p>
<p>This is a case where I extract a relatively coarse density estimate a priori. Subsequently, this small, stored estimate, is what is actually used to regenerate an accurate simulation of the original model output. This means no inefficient, slow lugging around of big data. Compress it down, release it in similar to original form later.</p>
<p>The following is used in the <code>AR4_AR5_extract.R</code> script which is part of the SNAP data QA/QC project and feeds into the Shiny app for comparing CMIP3 and CMIP5 downscaled climate model outputs. There is a function for estimating densities. In this case I wanted to avoid any <code>NA</code> values and for precipitation I wanted to ensure densities did not include positive probability over any interval containing negative values. The only other variable being analyzed was temperature. Things like this are important to code for in nuanced ways when the goal is to apply such a function to a large number of datasets. Effort must go into dealing with rare idiosyncrasies in the data and their effects.</p>
<pre class="sourceCode r"><code class="sourceCode r">denFun &lt;-<span class="st"> </span>function(x, n, variable) {
    x &lt;-<span class="st"> </span>x[!<span class="kw">is.na</span>(x)]
    dif &lt;-<span class="st"> </span><span class="kw">diff</span>(<span class="kw">range</span>(x))
    z &lt;-<span class="st"> </span><span class="kw">density</span>(x, <span class="dt">adjust =</span> <span class="dv">2</span>, <span class="dt">n =</span> n, <span class="dt">from =</span> <span class="kw">min</span>(x) -<span class="st"> </span><span class="fl">0.05</span> *<span class="st"> </span>dif, <span class="dt">to =</span> <span class="kw">max</span>(x) +<span class="st"> </span>
<span class="st">        </span><span class="fl">0.05</span> *<span class="st"> </span>dif)
    if (variable ==<span class="st"> &quot;pr&quot;</span> &amp;&amp;<span class="st"> </span><span class="kw">any</span>(z$x &lt;<span class="st"> </span><span class="dv">0</span>)) 
        z &lt;-<span class="st"> </span><span class="kw">density</span>(x, <span class="dt">adjust =</span> <span class="dv">2</span>, <span class="dt">n =</span> n, <span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="kw">max</span>(x) +<span class="st"> </span><span class="fl">0.05</span> *<span class="st"> </span>dif)
    <span class="kw">as.numeric</span>(<span class="kw">c</span>(z$x, z$y))
}</code></pre>
<p>On the other end, in this case tucked within the aforementioned Shiny app, the function, <code>density2bootstrap</code> is used to simulate new draws from the estimated density. This is much faster and more efficient than trying to load an enormous data set. In this app, the <code>ggplo2</code> graphics rely on the sample for plotting which is why the bootstrapping occurs following loading of the density estimate, and why there is no subsequent code for fitting a new density estimate to the bootstrap sample.</p>
<pre class="sourceCode r"><code class="sourceCode r">density2bootstrap &lt;-<span class="st"> </span>function(d, n.density, <span class="dt">n.boot =</span> <span class="dv">10000</span>, <span class="dt">interp =</span> <span class="ot">FALSE</span>, 
    <span class="dt">n.interp =</span> <span class="dv">1000</span>, ...) {
    n.fact &lt;-<span class="st"> </span>n.boot/n.density
    n.grp &lt;-<span class="st"> </span><span class="kw">nrow</span>(d)/n.density
    d$Index &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>:n.grp, <span class="dt">each =</span> n.density)
    d2 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">lapply</span>(d, rep, n.fact), <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)
    prob.col &lt;-<span class="st"> </span><span class="kw">which</span>(<span class="kw">names</span>(d2) %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Prob&quot;</span>, <span class="st">&quot;Index&quot;</span>))
    d2 &lt;-<span class="st"> </span>d2[<span class="kw">order</span>(d2$Index), -prob.col]
    d2$Val &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">vapply</span>(<span class="dt">X =</span> <span class="dv">1</span>:n.grp, <span class="dt">FUN =</span> function(i, d, n, interp, 
        n.interp, ...) {
        p &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">x =</span> d$Val[d$Index ==<span class="st"> </span>i], <span class="dt">y =</span> d$Prob[d$Index ==<span class="st"> </span>i])
        if (interp) p &lt;-<span class="st"> </span><span class="kw">approx</span>(p$x, p$y, <span class="dt">n =</span> n.interp)
        <span class="kw">round</span>(<span class="kw">sample</span>(p$x, n, <span class="dt">prob =</span> p$y, <span class="dt">rep =</span> T), ...)
    }, <span class="dt">FUN.VALUE =</span> <span class="kw">numeric</span>(n.boot), <span class="dt">d =</span> d, <span class="dt">n =</span> n.boot, <span class="dt">interp =</span> interp, <span class="dt">n.interp =</span> n.interp, 
        ...))
    d2
}</code></pre>
<p>However, for a complete picture of how these functions work together, it is important to see the documentation for the projects of which they are a part.</p>
</div>
<div id="use-case-2-vegetation" class="section level2">
<h2>Use case 2: Vegetation</h2>
<p>The motivation and the context for vegetation area and age distributions from SNAP’s ALFRESCO model ouput are the same as with use case one. However, the data are different. Through preliminary investigation, I can make changes to my approach, such as requiring a greater initial sample size or some other change that will maintain accuracy, which conceivably will differ for different random variables, data sets, and forms of variability and uncertainty involved. In this case I do something very similar to above.</p>
<p>As in the case of climate, there is a similar function for estimating densities storing only minimal information. However, with this data there were more things to look out for, such as entirely missing data or all data consisting of a single unique value (e.g., all modeled vegetation ages in one subregion are the same age in the ALFRESCO model), and how these situations are to be handled.</p>
<p>Furthermore, depending on how they are handled, which to some extent depends on how I eventually plan to use these estimated distributions, there are different potential consequences arising from other internal forms of sample. For instance, if all cells in a map layer of a given vegetation class are of the same age, do I want to sample with some kernal located on that value, knowing that these ages are not all the same in reality? On the other hand, I could return nothing but <code>NA</code> values if I am not satisfied with certain circumstances, as shown in the subsequent version of <code>denFun</code> which is applied to vegetated area rather than age.</p>
<pre class="sourceCode r"><code class="sourceCode r">denFun &lt;-<span class="st"> </span>function(x, n, <span class="dt">min.zero =</span> <span class="ot">TRUE</span>, <span class="dt">diversify =</span> <span class="ot">FALSE</span>) {
    x &lt;-<span class="st"> </span>x[!<span class="kw">is.na</span>(x)]
    lx &lt;-<span class="st"> </span><span class="kw">length</span>(x)
    if (diversify &amp;&amp;<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(x)) ==<span class="st"> </span><span class="dv">1</span>) 
        x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="kw">max</span>(<span class="dv">10</span>, lx), <span class="dt">mean =</span> x[<span class="dv">1</span>])  <span class="co"># diversify constant values</span>
    if (lx ==<span class="st"> </span><span class="dv">1</span>) 
        x &lt;-<span class="st"> </span>x +<span class="st"> </span><span class="kw">c</span>(-<span class="dv">1</span>:<span class="dv">1</span>)  <span class="co">#single pixel of veg type, add and subtract one age year to make procedure possible</span>
    dif &lt;-<span class="st"> </span><span class="kw">diff</span>(<span class="kw">range</span>(x))
    z &lt;-<span class="st"> </span><span class="kw">density</span>(x, <span class="dt">adjust =</span> <span class="dv">2</span>, <span class="dt">n =</span> n, <span class="dt">from =</span> <span class="kw">min</span>(x) -<span class="st"> </span><span class="kw">max</span>(<span class="dv">1</span>, <span class="fl">0.05</span> *<span class="st"> </span>dif), <span class="dt">to =</span> <span class="kw">max</span>(x) +<span class="st"> </span>
<span class="st">        </span><span class="kw">max</span>(<span class="dv">1</span>, <span class="fl">0.05</span> *<span class="st"> </span>dif))
    if (min.zero &amp;&amp;<span class="st"> </span><span class="kw">any</span>(z$x &lt;<span class="st"> </span><span class="dv">0</span>)) 
        z &lt;-<span class="st"> </span><span class="kw">density</span>(x, <span class="dt">adjust =</span> <span class="dv">2</span>, <span class="dt">n =</span> n, <span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="kw">max</span>(x) +<span class="st"> </span><span class="kw">max</span>(<span class="dv">1</span>, <span class="fl">0.05</span> *<span class="st"> </span>
<span class="st">            </span>dif))
    <span class="kw">as.numeric</span>(<span class="kw">c</span>(z$x, z$y))
}</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">denFun &lt;-<span class="st"> </span>function(x, <span class="dt">n =</span> <span class="dv">20</span>, <span class="dt">min.zero =</span> <span class="ot">TRUE</span>, <span class="dt">diversify =</span> <span class="ot">FALSE</span>, <span class="dt">missing.veg.NA =</span> <span class="ot">TRUE</span>, 
    <span class="dt">fire =</span> <span class="ot">FALSE</span>) {
    if (<span class="kw">all</span>(<span class="kw">is.na</span>(x))) 
        <span class="kw">return</span>(<span class="kw">rep</span>(<span class="ot">NA</span>, <span class="dv">2</span> *<span class="st"> </span>n))
    x &lt;-<span class="st"> </span>x[!<span class="kw">is.na</span>(x)]
    lx &lt;-<span class="st"> </span><span class="kw">length</span>(x)
    if (<span class="kw">sum</span>(x) ==<span class="st"> </span><span class="dv">0</span> &amp;<span class="st"> </span>missing.veg.NA &amp;<span class="st"> </span>!fire) 
        <span class="kw">return</span>(<span class="kw">rep</span>(<span class="ot">NA</span>, <span class="dv">2</span> *<span class="st"> </span>n))
    if (diversify &amp;&amp;<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(x)) ==<span class="st"> </span><span class="dv">1</span>) 
        x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="kw">max</span>(<span class="dv">10</span>, lx), <span class="dt">mean =</span> x[<span class="dv">1</span>])  <span class="co"># diversify constant values</span>
    if (lx ==<span class="st"> </span><span class="dv">1</span>) 
        x &lt;-<span class="st"> </span>x +<span class="st"> </span><span class="kw">c</span>(-<span class="dv">1</span>:<span class="dv">1</span>)  <span class="co">#single pixel of veg type, add and subtract one age year to make procedure possible</span>
    dif &lt;-<span class="st"> </span><span class="kw">diff</span>(<span class="kw">range</span>(x))
    z &lt;-<span class="st"> </span><span class="kw">density</span>(x, <span class="dt">adjust =</span> <span class="dv">2</span>, <span class="dt">n =</span> n, <span class="dt">from =</span> <span class="kw">min</span>(x) -<span class="st"> </span><span class="kw">max</span>(<span class="dv">1</span>, <span class="fl">0.05</span> *<span class="st"> </span>dif), <span class="dt">to =</span> <span class="kw">max</span>(x) +<span class="st"> </span>
<span class="st">        </span><span class="kw">max</span>(<span class="dv">1</span>, <span class="fl">0.05</span> *<span class="st"> </span>dif))
    if (min.zero &amp;&amp;<span class="st"> </span><span class="kw">any</span>(z$x &lt;<span class="st"> </span><span class="dv">0</span>)) 
        z &lt;-<span class="st"> </span><span class="kw">density</span>(x, <span class="dt">adjust =</span> <span class="dv">2</span>, <span class="dt">n =</span> n, <span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="kw">max</span>(x) +<span class="st"> </span><span class="kw">max</span>(<span class="dv">1</span>, <span class="fl">0.05</span> *<span class="st"> </span>
<span class="st">            </span>dif))
    <span class="kw">as.numeric</span>(<span class="kw">c</span>(z$x, z$y))
}</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">btfun &lt;-<span class="st"> </span>function(p, <span class="dt">n.samples =</span> <span class="kw">length</span>(p)/<span class="dv">2</span>, <span class="dt">n.boot =</span> <span class="dv">10000</span>, <span class="dt">interp =</span> <span class="ot">FALSE</span>, 
    <span class="dt">n.interp =</span> <span class="dv">1000</span>, ...) {
    if (!<span class="kw">length</span>(p)) 
        <span class="kw">return</span>(p)
    if (<span class="kw">all</span>(<span class="kw">is.na</span>(p))) 
        <span class="kw">return</span>(<span class="kw">rep</span>(<span class="ot">NA</span>, n.boot))
    p &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">x =</span> p[<span class="dv">1</span>:n.samples], <span class="dt">y =</span> p[(n.samples +<span class="st"> </span><span class="dv">1</span>):(<span class="dv">2</span> *<span class="st"> </span>n.samples)])
    if (interp &amp;&amp;<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(p[<span class="dv">1</span>:n.samples])) &gt;<span class="st"> </span><span class="dv">1</span>) 
        p &lt;-<span class="st"> </span><span class="kw">approx</span>(p$x, p$y, <span class="dt">n =</span> n.interp)
    p &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">sample</span>(p$x, n.boot, <span class="dt">prob =</span> p$y, <span class="dt">rep =</span> T), ...)
    p
}</code></pre>
<p>Again, there is another case of bootstrap resampling from the estimated distributions to arrive at new simulated, representative draws from the original distribution. Think of it like teleporting to your destination instead of walking, specifically when you have a heavy pack. As with use case 1, it is helpful to see the documentation for the ALFRESCO output extraction and related projects to which these functions belong.</p>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>


</body>
</html>
