<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Matthew Leonawicz" />


<title>Data Extraction Evaluation</title>

<script src="libs/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.1/css/united.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.1/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.1/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.1/shim/respond.min.js"></script>
<style type="text/css">
/* padding for bootstrap navbar */
body {
padding-top: 50px;
padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar) */
.section h2 {
padding-top: 55px;
margin-top: -55px;
}
.section h3 {
padding-top: 55px;
margin-top: -55px;
}
/* don't use link color in navbar */
.dropdown-menu>li>a {
color: black;
}
/* some padding for disqus */
#disqus_thread {
margin-top: 45px;
}
</style>
<link rel="stylesheet" href="libs/font-awesome-4.1.0/css/font-awesome.min.css"/>




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-46129458-3', 'auto');
  ga('send', 'pageview');

</script>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}
</style>
<div class="container-fluid main-container">

<div class="navbar navbar-default navbar-fixed-top">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Data Extraction</a>
      </div>
      <div class="navbar-collapse collapse navbar-responsive-collapse">
        <ul class="nav navbar-nav">
          <li class="dropdown">
            <a href="extraction-evaluation" class="dropdown-toggle" data-toggle="dropdown">Extraction evaluation <b class="caret"></b></a>
            <ul class="dropdown-menu">
              <li class="dropdown-header">Project</li>
              <li><a href="eval_intro.html">Introduction</a></li>
              <li><a href="eval_case.html">Case study: sample mean</a></li>
              <li><a href="eval_res.html">Results</a></li>
              <li><a href="eval_next.html">Next steps</a></li>
              <li class="divider"></li>
              <li class="dropdown-header">R Code</li>
              <li><a href="extract_eval_code.html">Complete code</a></li>
            </ul>

          <li class="dropdown">
            <a href="density-estimation" class="dropdown-toggle" data-toggle="dropdown">Density estimation <b class="caret"></b></a>
            <ul class="dropdown-menu">
              <li class="dropdown-header">Project</li>
              <li><a href="dens_intro.html">Introduction</a></li>
              <li><a href="dens_sims.html">Simulations</a></li>
              <li class="divider"></li>
              <li class="dropdown-header">Use cases</li>
              <li><a href="dens_use1.html">Case 1: Climate</a></li>
              <li><a href="dens_use2.html">Case 2: Vegetation</a></li>
              <li class="divider"></li>
              <li class="dropdown-header">R code</li>
              <li><a href="dens_sims_code.html">Basic simulation</a></li>
            </ul>

          <li class="dropdown">
            <a href="pre-indexing" class="dropdown-toggle" data-toggle="dropdown">Pre-indexing <b class="caret"></b></a>
            <ul class="dropdown-menu">
              <li class="dropdown-header">Project</li>
              <li><a href="ind_intro.html">Introduction</a></li>
              <li><a href="ind_related.html">Related items</a></li>
              <li class="divider"></li>
              <li class="dropdown-header">R Code</li>
              <li><a href="ind_code.html">Complete code</a></li>
            </ul>

          <li><a href="http://leonawicz.github.io">All Projects</a></li>
        </ul>
        <ul class="nav navbar-nav navbar-right">
          <a class="btn btn-link" href="https://github.com/leonawicz/DataExtraction">
            <i class="fa fa-github fa-lg"></i>
            Github
          </a>
        </ul>
      </div><!--/.nav-collapse -->
    </div>
  </div>

<div id="header">
<h1 class="title">Data Extraction Evaluation</h1>
<h4 class="author"><em>Matthew Leonawicz</em></h4>
</div>


<div id="results" class="section level4">
<h4>Results</h4>
<div id="all-points-no-point." class="section level5">
<h5>All points? No point.</h5>
<p>Using the sample mean is helpful as a data reduction strategy while not being harmful in terms of representativeness. The possible “tradeoff” itself appears to be largely a false dichotomy. There is no benefit to computing the mean of all pixels in the example map layer.</p>
</div>
<div id="how-many-samples-do-we-really-need" class="section level5">
<h5>How many samples do we really need?</h5>
<p><img src="eval_res_files/figure-html/sigdig-1.png" /></p>
<p>In this example even a two percent subsample of the original non-NA data cells is small enough to limit us to a five percent probability of obtaining a mean that differs from the mean computed on the full dataset by an amount equal to or greater than the smallest discrete increment possible (0.1 degrees Celsius for SNAP temperature data) based simply on the number of significant figures present. Furthermore, even for nominal sample sizes, the 0.05 probability is one almost strictly of minimal deviation (0.1 degrees). The probability that a sample mean computed on a subsample of the map layer deviates enough from the population mean to cause it to be rounded to two discrete incremental units from the population mean (0.2 degrees) is essentially zero (except if using crudely small sample sizes).</p>
<p>Although a two percent subsample appears sufficient for this criterion, letâ€™s use a five percent subsample for illustration. This is clearly overkill in this example since the p-value attenuates to the range of 0.019 to 0.029 by around 2.5 percent subsampling.</p>
</div>
<div id="how-much-faster-does-this-make-things-go" class="section level5">
<h5>How much faster does this make things go?</h5>
<p>Compute time for the mean is of course affected by the sample size.</p>
<pre><code>## Unit: microseconds
##                          expr    min     lq     mean median     uq     max
##  sum(s005pct)/length(s005pct)  4.977  5.288  5.91272  5.599  5.599  97.035
##  sum(s010pct)/length(s010pct)  9.642  9.953 10.73492  9.953 10.264 476.772
##  sum(s025pct)/length(s025pct) 23.326 23.637 25.14469 23.638 23.949 992.418
##  sum(s100pct)/length(s100pct) 92.058 92.369 96.74378 92.370 93.303 604.284
##  neval
##  10000
##  10000
##  10000
##  10000</code></pre>
<p><img src="eval_res_files/figure-html/benchmarks3-1.png" /></p>
<p>Using optimal subsampling to estimate the mean achieves speed improvements orders of magnitude greater than what can be achieved through strictly algorithmic changes to how the mean is computed on the full dataset, though those help immensely as well, also by many orders of magnitude. Sampling is vastly more effective, but both approaches can be combined for maximum benefit.</p>
<pre><code>## Unit: microseconds
##                          expr        min          lq         mean
##  sum(s005pct)/length(s005pct)      5.599      6.0655     12.04002
##            mean(v, na.rm = T) 394803.414 400618.1245 413228.42811
##              sum(d)/length(d)   1487.539   1497.1800   1566.62766
##                 mean(s005pct)     17.728     20.5270     46.71396
##      median         uq        max neval
##       9.798     19.594     29.547   100
##  408871.581 421030.797 532075.836   100
##    1509.776   1567.157   2030.554   100
##      54.738     63.757     92.058   100</code></pre>
<pre><code>## Unit: microseconds
##                          expr        min          lq         mean
##  sum(s005pct)/length(s005pct)      5.599      6.0655     12.04002
##            mean(v, na.rm = T) 394803.414 400618.1245 413228.42811
##              sum(d)/length(d)   1487.539   1497.1800   1566.62766
##                 mean(s005pct)     17.728     20.5270     46.71396
##      median         uq        max neval
##       9.798     19.594     29.547   100
##  408871.581 421030.797 532075.836   100
##    1509.776   1567.157   2030.554   100
##      54.738     63.757     92.058   100</code></pre>
<pre><code>## Unit: microseconds
##                          expr        min          lq         mean
##  sum(s005pct)/length(s005pct)      5.599      6.0655     12.04002
##            mean(v, na.rm = T) 394803.414 400618.1245 413228.42811
##              sum(d)/length(d)   1487.539   1497.1800   1566.62766
##                 mean(s005pct)     17.728     20.5270     46.71396
##      median         uq        max neval
##       9.798     19.594     29.547   100
##  408871.581 421030.797 532075.836   100
##    1509.776   1567.157   2030.554   100
##      54.738     63.757     92.058   100</code></pre>
<p><img src="eval_res_files/figure-html/benchmarks4-1.png" /></p>
<p>Similar to above, below are the median compute times for the mean using (1) the full data while removing NAs, (2) the sum divided by the length after NAs removed, (3) the mean of a subsample, and (4) a combination of (2) and (3).</p>
<p><img src="eval_res_files/figure-html/benchmarks4med1-1.png" /></p>
<p>Here is the same plot after removing the first bar to better show the relative compute time for the other three methods.</p>
<p><img src="eval_res_files/figure-html/benchmarks4med2-1.png" /></p>
<p>How does the benefit extend to extractions on maps at different extents, data heterogeneity, climate variables, or for other common statistics such as the standard deviation? These are open questions at the moment, but for one thing, I expect more samples are needed for precipitation than temperature. I also expect more samples needed to estimate parameters with higher moments.</p>
</div>
</div>

<!-- some extra javascript for older browsers -->
<script type="text/javascript" src="libs/polyfill.js"></script>
<script>
  // manage active state of menu based on current page
  $(document).ready(function () {
  
    // active menu
    href = window.location.pathname
    href = href.substr(href.lastIndexOf('/') + 1)
    $('a[href="' + href + '"]').parent().addClass('active');
    
    // manage active menu header
    if (href.startsWith('authoring_'))
      $('a[href="' + 'authoring' + '"]').parent().addClass('active');
    else if (href.endsWith('_format.html'))
      $('a[href="' + 'formats' + '"]').parent().addClass('active');
    else if (href.startsWith('developer_'))
      $('a[href="' + 'developer' + '"]').parent().addClass('active');
	  
  });
</script>

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>


</body>
</html>
